{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "### Import neccessary library"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "# !pip install tqdm"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "from bs4 import BeautifulSoup\r\n",
    "from selenium import webdriver\r\n",
    "import chromedriver_binary\r\n",
    "from selenium.webdriver.common.action_chains import ActionChains\r\n",
    "import pandas as pd\r\n",
    "from tqdm import tqdm\r\n",
    "import requests\r\n",
    "\r\n",
    "opts = webdriver.ChromeOptions()\r\n",
    "opts.headless = True\r\n",
    "browser = webdriver.Chrome(options=opts)\r\n",
    "browser.maximize_window()\r\n",
    "df = pd.DataFrame()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Get statistics of all NBA teams from last season"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "def get_old_stat(year):\r\n",
    "    url = f'https://www.basketball-reference.com/leagues/NBA_{year - 1}.html'\r\n",
    "    page = requests.get(url)\r\n",
    "\r\n",
    "    soup = BeautifulSoup(page.content, 'html.parser')\r\n",
    "\r\n",
    "    tbl = soup.find(\"table\",{\"id\":\"per_game-team\"})\r\n",
    "\r\n",
    "    df = pd.read_html(str(tbl))[0]\r\n",
    "    df['Team'] = df['Team'].str.replace('*', '', regex=False)\r\n",
    "    df.drop(df.tail(1).index, inplace=True)\r\n",
    "    df.to_csv('preseason_data.csv', header=True, index=False)\r\n",
    "    \r\n",
    "    with open('full_name.txt', 'w') as f:\r\n",
    "        for i, link in enumerate(tbl.find_all('a')):\r\n",
    "            short = link.get('href').split('/')[2]\r\n",
    "            f.write(short + ', ' + df['Team'][i] + '\\n')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Get NBA Team Elo"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "def get_elo(year):\r\n",
    "    url = f'https://projects.fivethirtyeight.com/{year - 1}-nba-predictions/'\r\n",
    "    if year == 2017:\r\n",
    "        url = 'https://projects.fivethirtyeight.com/2016-nba-picks/'\r\n",
    "    browser.get(url)\r\n",
    "    \r\n",
    "    name = 'teams-table' if year == 2017 else \"standings-table\"\r\n",
    "    \r\n",
    "    table = browser.find_element_by_id(name)\r\n",
    "    \r\n",
    "    body = table.find_element_by_tag_name('tbody')\r\n",
    "    rows = body.find_elements_by_tag_name('tr')\r\n",
    "    team_names = [r.find_element_by_class_name('team').text for r in rows]\r\n",
    "\r\n",
    "    dict_name = {}\r\n",
    "    with open('full_name.txt', 'r') as f:\r\n",
    "        for line in f:\r\n",
    "            name = line.split(',') # [short_name, full_name]\r\n",
    "            dict_name[name[0]] = name[1].strip()\r\n",
    "\r\n",
    "    for i, n in enumerate(team_names):        \r\n",
    "        for k in dict_name.keys():\r\n",
    "            if n in dict_name[k]:\r\n",
    "                team_names[i] = k\r\n",
    "                break\r\n",
    "            \r\n",
    "    with tqdm(rows) as pbar:\r\n",
    "        pbar.set_description(\"Get Elo\")        \r\n",
    "        team_elos = [r.find_element_by_tag_name('td').text for r in pbar]\r\n",
    "        \r\n",
    "    with open('preseason_elo.csv', 'w') as f:\r\n",
    "        f.write('Name, Elo\\n')\r\n",
    "        for n, e in zip(team_names, team_elos):\r\n",
    "            f.write(n + ', ' + e + '\\n')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Get colum descriptions"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "def get_description(year):\r\n",
    "    url = f'https://www.basketball-reference.com/leagues/NBA_{year - 1}.html'\r\n",
    "    browser.get(url)\r\n",
    "    \r\n",
    "    table = browser.find_element_by_id('per_game-team')\r\n",
    "    header = table.find_element_by_tag_name('thead')\r\n",
    "    col_tags = header.find_elements_by_tag_name('th')\r\n",
    "    date = ['Date']\r\n",
    "    \r\n",
    "    # create cols\r\n",
    "    sign = ['H_', 'A_']\r\n",
    "    cols = [c.text for c in col_tags]\r\n",
    "    tmp = [[sign[i] + c for c in cols] for i in range(2)]\r\n",
    "    col_table = date + tmp[0] + tmp[1]\r\n",
    "    \r\n",
    "    # create descriptions\r\n",
    "    sign_description = ['Home ', 'Away ']\r\n",
    "    with tqdm(col_tags) as pbar:\r\n",
    "        pbar.set_description(\"Get Description\")\r\n",
    "        desc = [c.get_attribute(\"data-tip\") \r\n",
    "                                    for c in pbar]\r\n",
    "    # Team description missing\r\n",
    "    desc[1] = 'Team'\r\n",
    "    \r\n",
    "    tmp = [[sign_description[i] + d for d in desc] for i in range(2)]\r\n",
    "    description = date + tmp[0] + tmp[1]\r\n",
    "    \r\n",
    "    with open('raw_description.txt', 'w') as f:\r\n",
    "        for c, d in zip(col_table, description):\r\n",
    "            f.write(c + ' : ' + d + '\\n')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Get URL to every match in a month"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "def get_html(url):\r\n",
    "    browser.get(url)\r\n",
    "    \r\n",
    "    btns = browser.find_elements_by_xpath('//*[@data-stat=\"box_score_text\"]')\r\n",
    "    btns = [b for b in btns if b.text != ' ']\r\n",
    "    links = [b.find_elements_by_xpath('.//*')[0].get_attribute('href') for b in btns]\r\n",
    "    \r\n",
    "    html_text = browser.page_source\r\n",
    "    \r\n",
    "    tree = BeautifulSoup(html_text, 'html.parser')\r\n",
    "    return links, tree"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Get column names"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "def get_info(url):\r\n",
    "    browser.get(url)\r\n",
    "\r\n",
    "    team = browser.find_element_by_id('line_score')\\\r\n",
    "                .find_element_by_tag_name('a').text\r\n",
    "\r\n",
    "    table = browser.find_element_by_id(f'box-{team}-game-basic')\r\n",
    "    \r\n",
    "    header = table.find_element_by_tag_name('thead')\r\n",
    "    col_tags = header.find_elements_by_tag_name('th')\r\n",
    "    date = ['Date']\r\n",
    "    \r\n",
    "    # create cols\r\n",
    "    sign = ['H_', 'A_']\r\n",
    "    cols = ['Team'] + [c.text for c in col_tags][3:]\r\n",
    "    tmp = [[sign[i] + c for c in cols] for i in range(2)]\r\n",
    "    col_table = date + tmp[0] + tmp[1]\r\n",
    "            \r\n",
    "    return col_table"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Get Data from every match"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "def get_data(url):\r\n",
    "    browser.get(url)\r\n",
    "    \r\n",
    "    datetime = browser.find_element_by_class_name('scorebox_meta')\\\r\n",
    "                        .find_element_by_tag_name('div').text\r\n",
    "    time, date = datetime.split(', ', 1)\r\n",
    "    \r\n",
    "    \r\n",
    "    tmp = browser.find_element_by_id('line_score')\\\r\n",
    "                .find_elements_by_tag_name('a')\r\n",
    "    teams = [t.text for t in tmp][::-1] # reverse() // home first\r\n",
    "\r\n",
    "    tables = [browser.find_element_by_id(f'box-{t}-game-basic') \r\n",
    "                                for t in teams]\r\n",
    "    data_table = [date]\r\n",
    "    for i, t in enumerate(tables):\r\n",
    "        footer = t.find_element_by_tag_name('tfoot')\r\n",
    "        data_tags = footer.find_elements_by_tag_name('td')\r\n",
    "        data = [teams[i]] + [d.text for d in data_tags]\r\n",
    "        data_table += data\r\n",
    "    \r\n",
    "    \r\n",
    "    return data_table"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Main "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "main_url = 'https://www.basketball-reference.com'\r\n",
    "cur_year = 2021\r\n",
    "n = 5\r\n",
    "years = [cur_year - i for i in range(n - 1, -1, -1)]\r\n",
    "\r\n",
    "cols = []\r\n",
    "\r\n",
    "get_elo(years[0])\r\n",
    "get_old_stat(years[0])\r\n",
    "get_description(years[0])\r\n",
    "\r\n",
    "for year in years:\r\n",
    "    print(year)\r\n",
    "    year_url = f'/leagues/NBA_{year}_games.html'\r\n",
    "    urls, tree = get_html(main_url + year_url)\r\n",
    "\r\n",
    "    filter = tree.find('div', class_=['filter'])\r\n",
    "\r\n",
    "    for i, tag in enumerate(filter.find_all('a')):\r\n",
    "        if i: # first link same with main page // no need to get html\r\n",
    "            link = main_url + tag['href']\r\n",
    "            urls, tree = get_html(link)\r\n",
    "            \r\n",
    "        with tqdm(urls) as pbar:\r\n",
    "            pbar.set_description(\"Processing %s\" % tag.text)\r\n",
    "            for link in pbar:\r\n",
    "                if not cols:\r\n",
    "                    cols = get_info(link)\r\n",
    "                    df = pd.DataFrame(columns=cols)\r\n",
    "\r\n",
    "                df = df.append(pd.DataFrame([get_data(link)], columns=cols),\r\n",
    "                               ignore_index = True)\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Get Elo: 100%|█████████████████████████████████████████████████████████████████████████| 30/30 [00:00<00:00, 60.34it/s]\n",
      "Get Description: 100%|████████████████████████████████████████████████████████████████| 25/25 [00:00<00:00, 216.08it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "2017\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Processing October: 100%|██████████████████████████████████████████████████████████████| 45/45 [01:06<00:00,  1.48s/it]\n",
      "Processing November: 100%|███████████████████████████████████████████████████████████| 229/229 [05:56<00:00,  1.56s/it]\n",
      "Processing December: 100%|███████████████████████████████████████████████████████████| 232/232 [06:08<00:00,  1.59s/it]\n",
      "Processing January: 100%|████████████████████████████████████████████████████████████| 223/223 [05:39<00:00,  1.52s/it]\n",
      "Processing February: 100%|███████████████████████████████████████████████████████████| 165/165 [04:10<00:00,  1.52s/it]\n",
      "Processing March: 100%|██████████████████████████████████████████████████████████████| 241/241 [06:29<00:00,  1.62s/it]\n",
      "Processing April: 100%|██████████████████████████████████████████████████████████████| 140/140 [03:37<00:00,  1.56s/it]\n",
      "Processing May: 100%|██████████████████████████████████████████████████████████████████| 29/29 [00:44<00:00,  1.53s/it]\n",
      "Processing June: 100%|███████████████████████████████████████████████████████████████████| 5/5 [00:08<00:00,  1.69s/it]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "2018\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Processing October: 100%|████████████████████████████████████████████████████████████| 104/104 [03:30<00:00,  2.03s/it]\n",
      "Processing November: 100%|███████████████████████████████████████████████████████████| 213/213 [06:58<00:00,  1.97s/it]\n",
      "Processing December: 100%|███████████████████████████████████████████████████████████| 227/227 [07:34<00:00,  2.00s/it]\n",
      "Processing January: 100%|████████████████████████████████████████████████████████████| 216/216 [07:10<00:00,  1.99s/it]\n",
      "Processing February: 100%|███████████████████████████████████████████████████████████| 160/160 [05:21<00:00,  2.01s/it]\n",
      "Processing March: 100%|██████████████████████████████████████████████████████████████| 222/222 [08:04<00:00,  2.18s/it]\n",
      "Processing April: 100%|██████████████████████████████████████████████████████████████| 136/136 [05:10<00:00,  2.28s/it]\n",
      "Processing May: 100%|██████████████████████████████████████████████████████████████████| 31/31 [01:09<00:00,  2.23s/it]\n",
      "Processing June: 100%|███████████████████████████████████████████████████████████████████| 3/3 [00:07<00:00,  2.39s/it]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "2019\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Processing October: 100%|████████████████████████████████████████████████████████████| 110/110 [04:15<00:00,  2.33s/it]\n",
      "Processing November: 100%|███████████████████████████████████████████████████████████| 219/219 [08:25<00:00,  2.31s/it]\n",
      "Processing December: 100%|███████████████████████████████████████████████████████████| 219/219 [08:10<00:00,  2.24s/it]\n",
      "Processing January: 100%|████████████████████████████████████████████████████████████| 221/221 [08:16<00:00,  2.25s/it]\n",
      "Processing February: 100%|███████████████████████████████████████████████████████████| 158/158 [06:04<00:00,  2.31s/it]\n",
      "Processing March: 100%|██████████████████████████████████████████████████████████████| 224/224 [08:37<00:00,  2.31s/it]\n",
      "Processing April: 100%|██████████████████████████████████████████████████████████████| 127/127 [04:51<00:00,  2.30s/it]\n",
      "Processing May: 100%|██████████████████████████████████████████████████████████████████| 29/29 [01:04<00:00,  2.24s/it]\n",
      "Processing June: 100%|███████████████████████████████████████████████████████████████████| 5/5 [00:12<00:00,  2.41s/it]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "2020\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Processing October 2019: 100%|█████████████████████████████████████████████████████████| 68/68 [02:39<00:00,  2.35s/it]\n",
      "Processing November: 100%|███████████████████████████████████████████████████████████| 215/215 [08:23<00:00,  2.34s/it]\n",
      "Processing December: 100%|███████████████████████████████████████████████████████████| 220/220 [08:32<00:00,  2.33s/it]\n",
      "Processing January: 100%|████████████████████████████████████████████████████████████| 222/222 [08:38<00:00,  2.34s/it]\n",
      "Processing February: 100%|███████████████████████████████████████████████████████████| 168/168 [06:24<00:00,  2.29s/it]\n",
      "Processing March: 100%|████████████████████████████████████████████████████████████████| 78/78 [02:57<00:00,  2.28s/it]\n",
      "Processing July: 100%|███████████████████████████████████████████████████████████████████| 8/8 [00:18<00:00,  2.28s/it]\n",
      "Processing August: 100%|█████████████████████████████████████████████████████████████| 123/123 [04:45<00:00,  2.32s/it]\n",
      "Processing September: 100%|████████████████████████████████████████████████████████████| 36/36 [01:22<00:00,  2.30s/it]\n",
      "Processing October 2020: 100%|███████████████████████████████████████████████████████████| 5/5 [00:10<00:00,  2.11s/it]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "2021\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Processing December: 100%|█████████████████████████████████████████████████████████████| 67/67 [02:42<00:00,  2.43s/it]\n",
      "Processing January: 100%|████████████████████████████████████████████████████████████| 222/222 [08:40<00:00,  2.35s/it]\n",
      "Processing February: 100%|███████████████████████████████████████████████████████████| 212/212 [08:11<00:00,  2.32s/it]\n",
      "Processing March: 100%|██████████████████████████████████████████████████████████████| 204/204 [07:55<00:00,  2.33s/it]\n",
      "Processing April: 100%|██████████████████████████████████████████████████████████████| 240/240 [09:23<00:00,  2.35s/it]\n",
      "Processing May: 100%|████████████████████████████████████████████████████████████████| 173/173 [06:33<00:00,  2.27s/it]\n",
      "Processing June: 100%|█████████████████████████████████████████████████████████████████| 45/45 [01:41<00:00,  2.25s/it]\n",
      "Processing July: 100%|███████████████████████████████████████████████████████████████████| 8/8 [00:17<00:00,  2.17s/it]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "df.shape"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(6247, 43)"
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "df = df.iloc[::-1] # reverse dataframe // from lastest -> oldest\r\n",
    "df.head()\r\n",
    "df.to_csv('raw_data.csv', index=False)\r\n",
    "browser.quit()"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}