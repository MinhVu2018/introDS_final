{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8b1e18ea",
   "metadata": {},
   "source": [
    "## Crawl NBA games' stats (~4h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "451301a9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tqdm in c:\\users\\mvc\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (4.62.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\mvc\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tqdm) (0.4.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install tqdm # progress bar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "84aad183",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "import chromedriver_binary\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import requests\n",
    "\n",
    "opts = webdriver.ChromeOptions()\n",
    "opts.headless = True\n",
    "browser = webdriver.Chrome(options=opts)\n",
    "browser.maximize_window()\n",
    "df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14eb232b",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a8792b5",
   "metadata": {},
   "source": [
    "1. Crawl teams and games data from [basketball-reference.com](https://www.basketball-reference.com) \n",
    "- Check term of service https://www.sports-reference.com/termsofuse.html <br>\n",
    "(using is welcomed but explicitly credit SRL as the source of the data + must not use this data to compete their services + must not submit virus, trojan,... + must not violate any express restrictions) \n",
    "2. Crawl preseason elo from [projects.fivethirtyeight.com](https://projects.fivethirtyeight.com)\n",
    "- Check term of service https://disneytermsofuse.com/english <br>\n",
    "(not allow to introduce a virus or other harmful component + maybe receive advertisements, promotions,...) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffd2db3a",
   "metadata": {},
   "source": [
    "### Get statistics of all NBA teams from last season"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "544a6a6c",
   "metadata": {},
   "source": [
    "Crawl old stat data from last season to create:\n",
    "- <b>\"preseason_data.csv\"</b>: Teams' average stats from last season\n",
    "- <b>\"full_name.txt\"</b>: All NBA teams' name and their abbreviations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "887c8a18",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_old_stat(year):\n",
    "    url = f'https://www.basketball-reference.com/leagues/NBA_{year - 1}.html'\n",
    "    page = requests.get(url)\n",
    "\n",
    "    soup = BeautifulSoup(page.content, 'html.parser')\n",
    "\n",
    "    tbl = soup.find(\"table\",{\"id\":\"per_game-team\"})\n",
    "\n",
    "    df = pd.read_html(str(tbl))[0]\n",
    "    df['Team'] = df['Team'].str.replace('*', '', regex=False)\n",
    "    df.drop(df.tail(1).index, inplace=True)\n",
    "    df.to_csv('preseason_data.csv', header=True, index=False)\n",
    "    \n",
    "    with open('full_name.txt', 'w') as f:\n",
    "        for i, link in enumerate(tbl.find_all('a')):\n",
    "            short = link.get('href').split('/')[2]\n",
    "            f.write(short + ', ' + df['Team'][i] + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1402a076",
   "metadata": {},
   "source": [
    "### Get NBA Team Elo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66d1d95b",
   "metadata": {},
   "source": [
    "Crawl NBA teams' elo from last season: <b>Data available from Season 2016-2017 -> now</b> <br>\n",
    "\n",
    "Season 2015-2016, url: 'https://projects.fivethirtyeight.com/2016-nba-picks/'    //(<b>\"nba-picks\"</b>)<br>\n",
    "Season 2016-2017-> now, url: 'https://projects.fivethirtyeight.com/${year}-nba-predictions/ <br>\n",
    "\n",
    "Then, create <b>\"preseason_elo.csv\"</b>: All NBA Team's elo from last season"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5cfcfdd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_elo(year):\n",
    "    url = f'https://projects.fivethirtyeight.com/{year - 1}-nba-predictions/'\n",
    "    if year == 2017:\n",
    "        url = 'https://projects.fivethirtyeight.com/2016-nba-picks/'\n",
    "    browser.get(url)\n",
    "    \n",
    "    name = 'teams-table' if year == 2017 else \"standings-table\"\n",
    "    \n",
    "    table = browser.find_element_by_id(name)\n",
    "    \n",
    "    body = table.find_element_by_tag_name('tbody')\n",
    "    rows = body.find_elements_by_tag_name('tr')\n",
    "    team_names = [r.find_element_by_class_name('team').text for r in rows]\n",
    "\n",
    "    dict_name = {}\n",
    "    with open('full_name.txt', 'r') as f:\n",
    "        for line in f:\n",
    "            name = line.split(',') # [short_name, full_name]\n",
    "            dict_name[name[0]] = name[1].strip()\n",
    "\n",
    "    for i, n in enumerate(team_names):        \n",
    "        for k in dict_name.keys():\n",
    "            if n in dict_name[k]:\n",
    "                team_names[i] = k\n",
    "                break\n",
    "            \n",
    "    with tqdm(rows) as pbar:\n",
    "        pbar.set_description(\"Get Elo\")        \n",
    "        team_elos = [r.find_element_by_tag_name('td').text for r in pbar]\n",
    "        \n",
    "    with open('preseason_elo.csv', 'w') as f:\n",
    "        f.write('Name, Elo\\n')\n",
    "        for n, e in zip(team_names, team_elos):\n",
    "            f.write(n + ', ' + e + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b12e8d0e",
   "metadata": {},
   "source": [
    "### Get colum descriptions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "931b9bb8",
   "metadata": {},
   "source": [
    "Crawl data to create <b>\"raw_description.txt\"</b>: Get stats' names and their descriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "14db38ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_description(year):\n",
    "    url = f'https://www.basketball-reference.com/leagues/NBA_{year - 1}.html'\n",
    "    browser.get(url)\n",
    "    \n",
    "    table = browser.find_element_by_id('per_game-team')\n",
    "    header = table.find_element_by_tag_name('thead')\n",
    "    col_tags = header.find_elements_by_tag_name('th')\n",
    "    date = ['Date']\n",
    "    \n",
    "    # create cols\n",
    "    sign = ['H_', 'A_']\n",
    "    cols = [c.text for c in col_tags]\n",
    "    tmp = [[sign[i] + c for c in cols] for i in range(2)]\n",
    "    col_table = date + tmp[0] + tmp[1]\n",
    "    \n",
    "    # create descriptions\n",
    "    sign_description = ['Home ', 'Away ']\n",
    "    with tqdm(col_tags) as pbar:\n",
    "        pbar.set_description(\"Get Description\")\n",
    "        desc = [c.get_attribute(\"data-tip\") \n",
    "                                    for c in pbar]\n",
    "    # Team description missing\n",
    "    desc[1] = 'Team'\n",
    "    \n",
    "    tmp = [[sign_description[i] + d for d in desc] for i in range(2)]\n",
    "    description = date + tmp[0] + tmp[1]\n",
    "    \n",
    "    with open('raw_description.txt', 'w') as f:\n",
    "        for c, d in zip(col_table, description):\n",
    "            f.write(c + ' : ' + d + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4adbfba",
   "metadata": {},
   "source": [
    "### Get URL to every match in a month"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "423da244",
   "metadata": {},
   "source": [
    "Create url for games' stats in each month in 1 season"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d01ed9b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_html(url):\n",
    "    browser.get(url)\n",
    "    \n",
    "    btns = browser.find_elements_by_xpath('//*[@data-stat=\"box_score_text\"]')\n",
    "    btns = [b for b in btns if b.text != ' ']\n",
    "    links = [b.find_elements_by_xpath('.//*')[0].get_attribute('href') for b in btns]\n",
    "    \n",
    "    html_text = browser.page_source\n",
    "    \n",
    "    tree = BeautifulSoup(html_text, 'html.parser')\n",
    "    return links, tree"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9888601",
   "metadata": {},
   "source": [
    "### Get column names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b1e4618",
   "metadata": {},
   "source": [
    "Generate column names for dataframe (column name = symbol('H' or 'A') + stat_name) <br>\n",
    "H_: Home team's stats <br>\n",
    "A_: Away team's stats <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "59b8530a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_info(url):\n",
    "    browser.get(url)\n",
    "\n",
    "    team = browser.find_element_by_id('line_score')\\\n",
    "                .find_element_by_tag_name('a').text\n",
    "\n",
    "    table = browser.find_element_by_id(f'box-{team}-game-basic')\n",
    "    \n",
    "    header = table.find_element_by_tag_name('thead')\n",
    "    col_tags = header.find_elements_by_tag_name('th')\n",
    "    date = ['Date']\n",
    "    \n",
    "    # create cols\n",
    "    sign = ['H_', 'A_']\n",
    "    cols = ['Team'] + [c.text for c in col_tags][3:]\n",
    "    tmp = [[sign[i] + c for c in cols] for i in range(2)]\n",
    "    col_table = date + tmp[0] + tmp[1]\n",
    "            \n",
    "    return col_table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc16beb9",
   "metadata": {},
   "source": [
    "### Get Data from every match"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "341faf36",
   "metadata": {},
   "source": [
    "Crawl 1 game's stats based on column names above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "70f3d882",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(url):\n",
    "    browser.get(url)\n",
    "    \n",
    "    datetime = browser.find_element_by_class_name('scorebox_meta')\\\n",
    "                        .find_element_by_tag_name('div').text\n",
    "    time, date = datetime.split(', ', 1)\n",
    "    \n",
    "    \n",
    "    tmp = browser.find_element_by_id('line_score')\\\n",
    "                .find_elements_by_tag_name('a')\n",
    "    teams = [t.text for t in tmp][::-1] # reverse() // home first\n",
    "\n",
    "    tables = [browser.find_element_by_id(f'box-{t}-game-basic') \n",
    "                                for t in teams]\n",
    "    data_table = [date]\n",
    "    for i, t in enumerate(tables):\n",
    "        footer = t.find_element_by_tag_name('tfoot')\n",
    "        data_tags = footer.find_elements_by_tag_name('td')\n",
    "        data = [teams[i]] + [d.text for d in data_tags]\n",
    "        data_table += data\n",
    "    \n",
    "    \n",
    "    return data_table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7024c099",
   "metadata": {},
   "source": [
    "### Main "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cc34c89",
   "metadata": {},
   "source": [
    "Init current year: 2021 <br>\n",
    "Generate recent n years(in this case: n = 5) <br>\n",
    "Crawl stats, elo from preseason (current year - n - 1) <br>\n",
    "Crawl all games' data during n years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5eb2d7c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Get Elo: 100%|█████████████████████████████████████████████████████████████████████████| 30/30 [00:00<00:00, 64.78it/s]\n",
      "Get Description: 100%|████████████████████████████████████████████████████████████████| 25/25 [00:00<00:00, 211.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing October: 100%|██████████████████████████████████████████████████████████████| 45/45 [01:36<00:00,  2.14s/it]\n",
      "Processing November: 100%|███████████████████████████████████████████████████████████| 229/229 [08:24<00:00,  2.20s/it]\n",
      "Processing December: 100%|███████████████████████████████████████████████████████████| 232/232 [08:35<00:00,  2.22s/it]\n",
      "Processing January: 100%|████████████████████████████████████████████████████████████| 223/223 [08:19<00:00,  2.24s/it]\n",
      "Processing February: 100%|███████████████████████████████████████████████████████████| 165/165 [05:48<00:00,  2.11s/it]\n",
      "Processing March: 100%|██████████████████████████████████████████████████████████████| 241/241 [09:34<00:00,  2.38s/it]\n",
      "Processing April: 100%|██████████████████████████████████████████████████████████████| 140/140 [04:50<00:00,  2.07s/it]\n",
      "Processing May: 100%|██████████████████████████████████████████████████████████████████| 29/29 [01:01<00:00,  2.13s/it]\n",
      "Processing June: 100%|███████████████████████████████████████████████████████████████████| 5/5 [00:10<00:00,  2.16s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing October: 100%|████████████████████████████████████████████████████████████| 104/104 [03:45<00:00,  2.17s/it]\n",
      "Processing November: 100%|███████████████████████████████████████████████████████████| 213/213 [07:32<00:00,  2.12s/it]\n",
      "Processing December: 100%|███████████████████████████████████████████████████████████| 227/227 [08:03<00:00,  2.13s/it]\n",
      "Processing January: 100%|████████████████████████████████████████████████████████████| 216/216 [07:24<00:00,  2.06s/it]\n",
      "Processing February: 100%|███████████████████████████████████████████████████████████| 160/160 [05:38<00:00,  2.11s/it]\n",
      "Processing March: 100%|██████████████████████████████████████████████████████████████| 222/222 [07:47<00:00,  2.11s/it]\n",
      "Processing April: 100%|██████████████████████████████████████████████████████████████| 136/136 [04:44<00:00,  2.09s/it]\n",
      "Processing May: 100%|██████████████████████████████████████████████████████████████████| 31/31 [01:01<00:00,  2.00s/it]\n",
      "Processing June: 100%|███████████████████████████████████████████████████████████████████| 3/3 [00:05<00:00,  1.73s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing October: 100%|████████████████████████████████████████████████████████████| 110/110 [03:51<00:00,  2.11s/it]\n",
      "Processing November: 100%|███████████████████████████████████████████████████████████| 219/219 [07:47<00:00,  2.13s/it]\n",
      "Processing December: 100%|███████████████████████████████████████████████████████████| 219/219 [07:49<00:00,  2.14s/it]\n",
      "Processing January: 100%|████████████████████████████████████████████████████████████| 221/221 [08:08<00:00,  2.21s/it]\n",
      "Processing February: 100%|███████████████████████████████████████████████████████████| 158/158 [05:47<00:00,  2.20s/it]\n",
      "Processing March: 100%|██████████████████████████████████████████████████████████████| 224/224 [08:00<00:00,  2.15s/it]\n",
      "Processing April: 100%|██████████████████████████████████████████████████████████████| 127/127 [04:26<00:00,  2.10s/it]\n",
      "Processing May: 100%|██████████████████████████████████████████████████████████████████| 29/29 [01:01<00:00,  2.12s/it]\n",
      "Processing June: 100%|███████████████████████████████████████████████████████████████████| 5/5 [00:10<00:00,  2.14s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing October 2019: 100%|█████████████████████████████████████████████████████████| 68/68 [02:25<00:00,  2.14s/it]\n",
      "Processing November: 100%|███████████████████████████████████████████████████████████| 215/215 [08:18<00:00,  2.32s/it]\n",
      "Processing December: 100%|███████████████████████████████████████████████████████████| 220/220 [09:19<00:00,  2.54s/it]\n",
      "Processing January: 100%|████████████████████████████████████████████████████████████| 222/222 [08:32<00:00,  2.31s/it]\n",
      "Processing February: 100%|███████████████████████████████████████████████████████████| 168/168 [06:50<00:00,  2.44s/it]\n",
      "Processing March: 100%|████████████████████████████████████████████████████████████████| 78/78 [03:16<00:00,  2.52s/it]\n",
      "Processing July: 100%|███████████████████████████████████████████████████████████████████| 8/8 [00:18<00:00,  2.28s/it]\n",
      "Processing August: 100%|█████████████████████████████████████████████████████████████| 123/123 [04:48<00:00,  2.35s/it]\n",
      "Processing September: 100%|████████████████████████████████████████████████████████████| 36/36 [01:23<00:00,  2.31s/it]\n",
      "Processing October 2020: 100%|███████████████████████████████████████████████████████████| 5/5 [00:10<00:00,  2.17s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing December: 100%|█████████████████████████████████████████████████████████████| 67/67 [02:48<00:00,  2.51s/it]\n",
      "Processing January: 100%|████████████████████████████████████████████████████████████| 222/222 [09:08<00:00,  2.47s/it]\n",
      "Processing February: 100%|███████████████████████████████████████████████████████████| 212/212 [08:51<00:00,  2.51s/it]\n",
      "Processing March: 100%|██████████████████████████████████████████████████████████████| 204/204 [09:34<00:00,  2.81s/it]\n",
      "Processing April: 100%|██████████████████████████████████████████████████████████████| 240/240 [09:37<00:00,  2.41s/it]\n",
      "Processing May: 100%|████████████████████████████████████████████████████████████████| 173/173 [06:51<00:00,  2.38s/it]\n",
      "Processing June: 100%|█████████████████████████████████████████████████████████████████| 45/45 [01:40<00:00,  2.23s/it]\n",
      "Processing July: 100%|███████████████████████████████████████████████████████████████████| 8/8 [00:15<00:00,  1.88s/it]\n"
     ]
    }
   ],
   "source": [
    "main_url = 'https://www.basketball-reference.com'\n",
    "cur_year = 2021\n",
    "n = 5\n",
    "years = [cur_year - i for i in range(n - 1, -1, -1)]\n",
    "\n",
    "cols = []\n",
    "\n",
    "get_old_stat(years[0])\n",
    "get_elo(years[0])\n",
    "get_description(years[0])\n",
    "\n",
    "for year in years:\n",
    "    print(year)\n",
    "    year_url = f'/leagues/NBA_{year}_games.html'\n",
    "    urls, tree = get_html(main_url + year_url)\n",
    "\n",
    "    filter = tree.find('div', class_=['filter'])\n",
    "\n",
    "    for i, tag in enumerate(filter.find_all('a')):\n",
    "        if i: # first link same with main page // no need to get html\n",
    "            link = main_url + tag['href']\n",
    "            urls, tree = get_html(link)\n",
    "            \n",
    "        with tqdm(urls) as pbar:\n",
    "            pbar.set_description(\"Processing %s\" % tag.text)\n",
    "            for link in pbar:\n",
    "                if not cols:\n",
    "                    cols = get_info(link)\n",
    "                    df = pd.DataFrame(columns=cols)\n",
    "\n",
    "                df = df.append(pd.DataFrame([get_data(link)], columns=cols),\n",
    "                               ignore_index = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2aac67f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6247, 43)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a7bafe3",
   "metadata": {},
   "source": [
    "Save df to <b>\"raw_data.csv\"</b>: All NBA games' stats during n years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ec17d093",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.iloc[::-1] # reverse dataframe // from lastest -> oldest\n",
    "df.head()\n",
    "df.to_csv('raw_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bcc790fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "browser.quit()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
